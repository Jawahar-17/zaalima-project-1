{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13337480,"sourceType":"datasetVersion","datasetId":8457143}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üìä Task Management System - Exploratory Data Analysis\n\n## üéØ Project Objective\n\nThis analysis aims to extract actionable insights from a task management dataset to optimize team productivity, resource allocation, and project delivery. By analyzing task completion patterns, team performance, and workload distribution, we will:\n\n- **Identify bottlenecks** in task completion and resource utilization\n- **Understand task characteristics** that impact delivery time and success rates\n- **Optimize resource allocation** based on team performance and workload\n- **Improve estimation accuracy** by analyzing estimated vs. actual hours\n- **Enhance project planning** through data-driven insights\n\n---\n\n## üìã Business Context\n\n### Dataset Overview\nThis dataset contains **25,000 tasks** from a software development organization, tracking various aspects of task management including:\n\n**Task Attributes:**\n- Task identification (ID, title, description)\n- Classification (category, priority, status)\n- Timeline (created date, due date)\n- Effort metrics (estimated hours, actual hours, story points)\n\n**Resource Attributes:**\n- Team assignment (assigned_to, reporter, team)\n- Sprint planning (sprint, component)\n- User metrics (workload, experience, completion rate)\n- Collaboration indicators (number of comments)\n\n### Key Business Questions:\n1. **What is the distribution of tasks across categories, priorities, and teams?**\n2. **How do estimated hours compare to actual hours?**\n3. **Which teams or users have the highest completion rates?**\n4. **Is there a relationship between user experience and task completion efficiency?**\n5. **How does task priority affect estimated effort and actual delivery?**\n6. **Are there patterns in missing data that indicate process gaps?**\n\n---","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-30T10:37:10.869103Z","iopub.execute_input":"2025-10-30T10:37:10.869339Z","iopub.status.idle":"2025-10-30T10:37:11.139344Z","shell.execute_reply.started":"2025-10-30T10:37:10.869313Z","shell.execute_reply":"2025-10-30T10:37:11.138637Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/task-management/TASK MANAGEMENT.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## üìú Step 1: Data Loading & Initial Inspection\n\nIn this section, we will:\n- Load the task management dataset from CSV\n- Display the first few rows to understand the data structure\n- Check column names, data types, and basic information\n- Identify initial data quality indicators","metadata":{}},{"cell_type":"code","source":"# Load the CSV file into a pandas DataFrame\ndf = pd.read_csv('/kaggle/input/task-management/TASK MANAGEMENT.csv')\n\n# Display the first five rows\nprint(\"First 5 rows:\")\nprint(df.head())\n\n# Show column information\nprint(\"\\nColumn information:\")\ndf.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T10:37:11.140808Z","iopub.execute_input":"2025-10-30T10:37:11.141164Z","iopub.status.idle":"2025-10-30T10:37:11.358606Z","shell.execute_reply.started":"2025-10-30T10:37:11.141146Z","shell.execute_reply":"2025-10-30T10:37:11.357929Z"}},"outputs":[{"name":"stdout","text":"First 5 rows:\n       task_id                     task_title  \\\n0  TASK-000001             Debug dashboard UI   \n1  TASK-000002  Implement notification system   \n2  TASK-000003           Design data pipeline   \n3  TASK-000004            Update dashboard UI   \n4  TASK-000005           Debug CI/CD pipeline   \n\n                                    task_description     category  priority  \\\n0  Debug dashboard UI as per client requirements....      Bug Fix  Critical   \n1  Implement notification system to resolve issue...       Design  Critical   \n2  Design data pipeline to improve system functio...      Testing    Medium   \n3  Update dashboard UI as per client requirements...  Enhancement       Low   \n4  Enhancement request: Debug CI/CD pipeline. Sho...  Development    Medium   \n\n        status created_date    due_date  estimated_hours  actual_hours  \\\n0    Completed   2024-08-08  2024-08-10                2           2.9   \n1  In Progress   2025-01-03  2025-01-08               40           NaN   \n2         Open   2025-01-10  2025-01-29                8           NaN   \n3    Completed   2024-12-30  2025-01-17               16          15.3   \n4  In Progress   2024-01-18  2024-02-14               24           NaN   \n\n  assigned_to  reporter          team  story_points     sprint     component  \\\n0    User_098  User_049  Data Science             5  Sprint_15  Notification   \n1    User_072  User_040            QA             2   Sprint_3       Payment   \n2    User_062  User_076        DevOps             2   Sprint_6        Search   \n3    User_079  User_042        Mobile             2  Sprint_13        Search   \n4    User_057  User_072       Backend             2  Sprint_18           API   \n\n   user_workload  user_experience_months  user_completion_rate  num_comments  \n0            240                      63                  0.74             4  \n1            256                      73                  0.80             3  \n2            266                      64                  0.94             2  \n3            240                      11                  0.88             4  \n4            256                      16                  0.93             2  \n\nColumn information:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 25000 entries, 0 to 24999\nData columns (total 20 columns):\n #   Column                  Non-Null Count  Dtype  \n---  ------                  --------------  -----  \n 0   task_id                 25000 non-null  object \n 1   task_title              25000 non-null  object \n 2   task_description        25000 non-null  object \n 3   category                25000 non-null  object \n 4   priority                25000 non-null  object \n 5   status                  25000 non-null  object \n 6   created_date            25000 non-null  object \n 7   due_date                25000 non-null  object \n 8   estimated_hours         25000 non-null  int64  \n 9   actual_hours            8877 non-null   float64\n 10  assigned_to             25000 non-null  object \n 11  reporter                25000 non-null  object \n 12  team                    25000 non-null  object \n 13  story_points            25000 non-null  int64  \n 14  sprint                  25000 non-null  object \n 15  component               25000 non-null  object \n 16  user_workload           25000 non-null  int64  \n 17  user_experience_months  25000 non-null  int64  \n 18  user_completion_rate    25000 non-null  float64\n 19  num_comments            25000 non-null  int64  \ndtypes: float64(2), int64(5), object(13)\nmemory usage: 3.8+ MB\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## üßπ Step 2: Data Cleaning\n\nIn this section, we will:\n- Check for duplicate records and remove them\n- Identify missing values across all columns\n- Understand the pattern of missing data (especially in `actual_hours` which is only filled for completed tasks)\n- Verify data quality metrics after cleaning\n- Document the final shape and structure of the cleaned dataset\n\n### Expected Outcome:\n- Clean dataset ready for analysis\n- Clear understanding of missing data patterns\n- Documented data quality metrics","metadata":{}},{"cell_type":"code","source":"# Perform basic data cleaning\nprint(\"Data cleaning started...\\n\")\n\n# Check initial shape\nprint(f\"Initial shape: {df.shape}\")\nprint(f\"Initial duplicates: {df.duplicated().sum()}\\n\")\n\n# Drop duplicates\ndf = df.drop_duplicates()\nprint(f\"Shape after dropping duplicates: {df.shape}\")\n\n# Check for missing values\nprint(\"\\nMissing values per column:\")\nprint(df.isnull().sum())\n\n# Handle missing values in actual_hours\n# Since actual_hours is only filled for completed tasks, we'll keep NaN for non-completed tasks\nprint(\"\\nHandling missing values:\")\nprint(f\"- actual_hours has {df['actual_hours'].isnull().sum()} missing values\")\nprint(\"- These are expected for tasks that are not completed yet, so we'll keep them as NaN\")\n\n# Print cleaned data summary\nprint(\"\\n\" + \"=\"*50)\nprint(\"CLEANED DATA SUMMARY\")\nprint(\"=\"*50)\nprint(f\"Final shape: {df.shape}\")\nprint(f\"Total duplicates remaining: {df.duplicated().sum()}\")\nprint(f\"\\nMemory usage:\")\ndf.info(memory_usage='deep')\nprint(\"\\nData types:\")\nprint(df.dtypes)\nprint(\"\\nBasic statistics:\")\nprint(df.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T10:37:11.359492Z","iopub.execute_input":"2025-10-30T10:37:11.359757Z","iopub.status.idle":"2025-10-30T10:37:11.584865Z","shell.execute_reply.started":"2025-10-30T10:37:11.359720Z","shell.execute_reply":"2025-10-30T10:37:11.584117Z"}},"outputs":[{"name":"stdout","text":"Data cleaning started...\n\nInitial shape: (25000, 20)\nInitial duplicates: 0\n\nShape after dropping duplicates: (25000, 20)\n\nMissing values per column:\ntask_id                       0\ntask_title                    0\ntask_description              0\ncategory                      0\npriority                      0\nstatus                        0\ncreated_date                  0\ndue_date                      0\nestimated_hours               0\nactual_hours              16123\nassigned_to                   0\nreporter                      0\nteam                          0\nstory_points                  0\nsprint                        0\ncomponent                     0\nuser_workload                 0\nuser_experience_months        0\nuser_completion_rate          0\nnum_comments                  0\ndtype: int64\n\nHandling missing values:\n- actual_hours has 16123 missing values\n- These are expected for tasks that are not completed yet, so we'll keep them as NaN\n\n==================================================\nCLEANED DATA SUMMARY\n==================================================\nFinal shape: (25000, 20)\nTotal duplicates remaining: 0\n\nMemory usage:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 25000 entries, 0 to 24999\nData columns (total 20 columns):\n #   Column                  Non-Null Count  Dtype  \n---  ------                  --------------  -----  \n 0   task_id                 25000 non-null  object \n 1   task_title              25000 non-null  object \n 2   task_description        25000 non-null  object \n 3   category                25000 non-null  object \n 4   priority                25000 non-null  object \n 5   status                  25000 non-null  object \n 6   created_date            25000 non-null  object \n 7   due_date                25000 non-null  object \n 8   estimated_hours         25000 non-null  int64  \n 9   actual_hours            8877 non-null   float64\n 10  assigned_to             25000 non-null  object \n 11  reporter                25000 non-null  object \n 12  team                    25000 non-null  object \n 13  story_points            25000 non-null  int64  \n 14  sprint                  25000 non-null  object \n 15  component               25000 non-null  object \n 16  user_workload           25000 non-null  int64  \n 17  user_experience_months  25000 non-null  int64  \n 18  user_completion_rate    25000 non-null  float64\n 19  num_comments            25000 non-null  int64  \ndtypes: float64(2), int64(5), object(13)\nmemory usage: 24.0 MB\n\nData types:\ntask_id                    object\ntask_title                 object\ntask_description           object\ncategory                   object\npriority                   object\nstatus                     object\ncreated_date               object\ndue_date                   object\nestimated_hours             int64\nactual_hours              float64\nassigned_to                object\nreporter                   object\nteam                       object\nstory_points                int64\nsprint                     object\ncomponent                  object\nuser_workload               int64\nuser_experience_months      int64\nuser_completion_rate      float64\nnum_comments                int64\ndtype: object\n\nBasic statistics:\n       estimated_hours  actual_hours  story_points  user_workload  \\\ncount     25000.000000   8877.000000  25000.000000   25000.000000   \nmean         11.515520     12.568413      4.700200     250.965360   \nstd          13.256937     14.981412      3.781747      15.412893   \nmin           2.000000      1.400000      1.000000     208.000000   \n25%           4.000000      4.100000      2.000000     241.000000   \n50%           8.000000      7.700000      3.000000     253.000000   \n75%          16.000000     15.400000      5.000000     262.000000   \nmax          80.000000    119.800000     21.000000     283.000000   \n\n       user_experience_months  user_completion_rate  num_comments  \ncount            25000.000000          25000.000000  25000.000000  \nmean                58.043520              0.800446      2.991960  \nstd                 33.704776              0.097563      1.733694  \nmin                  6.000000              0.650000      0.000000  \n25%                 32.000000              0.710000      2.000000  \n50%                 56.000000              0.790000      3.000000  \n75%                 87.000000              0.890000      4.000000  \nmax                120.000000              0.980000     12.000000  \n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## üîç Step 3: Exploratory Data Analysis (EDA)\n\nNow that we have a clean dataset, we'll perform comprehensive EDA to uncover patterns, relationships, and insights that will drive data-driven decision making.\n\n### Analysis Roadmap:\n\n1. **Missing Data Visualization** - Visualize and analyze missing value patterns\n2. **Univariate Analysis** - Understand the distribution of individual variables\n   - Categorical variables (category, priority, status, team)\n   - Numerical variables (estimated_hours, actual_hours, story_points, user metrics)\n3. **Bivariate Analysis** - Explore relationships between variables\n   - Tasks by team and priority\n   - Estimated vs. actual hours by category\n   - User experience impact on completion rates\n   - Priority impact on task duration\n4. **Key Business Insights** - Summarize findings and actionable recommendations\n\n---","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# IMPORT VISUALIZATION LIBRARIES\n# ============================================================\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\n# Configuration for better visualizations\nwarnings.filterwarnings('ignore')\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (15, 6)\nplt.rcParams['font.size'] = 10\n\nprint(\"‚úÖ Visualization libraries imported successfully!\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T10:37:11.585696Z","iopub.execute_input":"2025-10-30T10:37:11.586231Z","iopub.status.idle":"2025-10-30T10:37:12.352711Z","shell.execute_reply.started":"2025-10-30T10:37:11.586205Z","shell.execute_reply":"2025-10-30T10:37:12.351895Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Visualization libraries imported successfully!\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Import EDA libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Visualize missing values\nplt.figure(figsize=(10,6))\nsns.heatmap(df.isnull(), cbar=False, cmap='viridis')\nplt.title('Missing Values Heatmap')\n\n# Examine categorical features\ncategorical_cols = df.select_dtypes(include=['object', 'category']).columns\nfor col in categorical_cols:\n    print(f\"\\nValue counts for {col}:\")\n    print(df[col].value_counts())\n    plt.figure(figsize=(8,3))\n    sns.countplot(data=df, x=col, order=df[col].value_counts().index)\n    plt.title(f'Distribution of {col}')\n    plt.xticks(rotation=45)\n    plt.show\n\n# Feature correlations (for numeric features)\nplt.figure(figsize=(10,8))\nsns.heatmap(df.select_dtypes(include=[np.number]).corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title('Feature Correlation Matrix')\nplt.show()\n\n# Examine relationships and outliers for numeric variables\nnumeric_cols = df.select_dtypes(include=[np.number]).columns\nfor col in numeric_cols:\n    plt.figure(figsize=(8,3))\n    sns.histplot(df[col], kde=True)\n    plt.title(f'Distribution of {col}')\n    plt.show()\n    sns.boxplot(data=df, x=col)\n    plt.title(f'Boxplot of {col}')\n    plt.show()\n\n# Pairplot to visualize pairwise relationships (sampled if the dataset is large)\nif len(df) < 1000:\n    sns.pairplot(df, hue='label' if 'label' in df.columns else None, diag_kind='kde')\n    plt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T10:37:12.354621Z","iopub.execute_input":"2025-10-30T10:37:12.354940Z"}},"outputs":[{"name":"stdout","text":"\nValue counts for task_id:\ntask_id\nTASK-025000    1\nTASK-000001    1\nTASK-000002    1\nTASK-000003    1\nTASK-000004    1\n              ..\nTASK-000012    1\nTASK-000013    1\nTASK-000014    1\nTASK-000015    1\nTASK-000016    1\nName: count, Length: 25000, dtype: int64\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## üß† Step 4: NLP Preprocessing (Text Cleaning)\n\nIn this section, we will perform comprehensive Natural Language Processing (NLP) preprocessing on the `task_description` column to prepare the text data for machine learning classification.\n\n### üéØ Objectives:\n- Convert raw task descriptions into clean, normalized text suitable for ML models\n- Reduce dimensionality while preserving semantic meaning\n- Create a new column `clean_task_description` with processed text\n\n### üìã NLP Preprocessing Steps:\n\n**1. Lowercase Conversion**\n   - Convert all text to lowercase for consistency\n   - Example: \"Fix Bug\" ‚Üí \"fix bug\"\n\n**2. Special Character Removal**\n   - Remove punctuation, digits, and special characters\n   - Keep only alphabetic characters and spaces\n   - Example: \"Update API-v2.0\" ‚Üí \"update api v\"\n\n**3. Tokenization**\n   - Split text into individual words (tokens)\n   - Example: \"fix the bug\" ‚Üí [\"fix\", \"the\", \"bug\"]\n\n**4. Stopword Removal**\n   - Remove common English words (the, is, at, etc.) that don't add semantic value\n   - Example: [\"fix\", \"the\", \"bug\"] ‚Üí [\"fix\", \"bug\"]\n\n**5. Lemmatization**\n   - Convert words to their root form\n   - Example: \"running\", \"runs\", \"ran\" ‚Üí \"run\"\n   - Preserves semantic meaning better than stemming\n\n**6. Short Word Filtering**\n   - Remove tokens with less than 3 characters\n   - Eliminates noise and meaningless tokens\n\n### üìä Expected Outcome:\n- Clean, normalized text ready for feature extraction\n- Reduced vocabulary size while preserving meaning\n- Enhanced model performance and reduced training time","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# NLP PREPROCESSING ON task_description COLUMN\n# ============================================================\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport re\n\n# Download required NLTK data\nprint(\"Downloading NLTK data...\")\nnltk.download('punkt', quiet=True)\nnltk.download('stopwords', quiet=True)\nnltk.download('wordnet', quiet=True)\nnltk.download('omw-1.4', quiet=True)\nprint(\"‚úÖ NLTK data downloaded successfully!\\n\")\n\n# Initialize lemmatizer and stopwords\nlemmatizer = WordNetLemmatizer()\nstop_words = set(stopwords.words('english'))\n\nprint(\"Starting NLP preprocessing...\\n\")\n\ndef preprocess_text(text):\n    \"\"\"\n    Perform NLP preprocessing: tokenization, stopword removal, and lemmatization\n    \"\"\"\n    # Convert to lowercase\n    text = text.lower()\n    \n    # Remove special characters and digits, keep only alphabets and spaces\n    text = re.sub(r'[^a-z\\s]', '', text)\n    \n    # Tokenization\n    tokens = word_tokenize(text)\n    \n    # Remove stopwords and lemmatize\n    cleaned_tokens = [\n        lemmatizer.lemmatize(word) \n        for word in tokens \n        if word not in stop_words and len(word) > 2\n    ]\n    \n    # Join tokens back to string\n    return ' '.join(cleaned_tokens)\n\n# Apply preprocessing to task_description column\ndf['clean_task_description'] = df['task_description'].apply(preprocess_text)\n\nprint(\"=\"*70)\nprint(\"NLP PREPROCESSING COMPLETED\")\nprint(\"=\"*70)\nprint(f\"\\nTotal tasks processed: {len(df)}\")\nprint(f\"New column 'clean_task_description' added to dataframe\\n\")\n\n# Print sample of original vs cleaned data\nprint(\"\\nSample comparison (Original vs Cleaned):\")\nprint(\"=\"*70)\nfor i in range(5):\n    print(f\"\\n[Task {i+1}]\")\n    print(f\"Original: {df['task_description'].iloc[i][:100]}...\")\n    print(f\"Cleaned:  {df['clean_task_description'].iloc[i][:100]}...\")\n    print(\"-\"*70)\n\n# Display statistics about cleaned text\nprint(\"\\nCleaned text statistics:\")\nprint(f\"Average token count: {df['clean_task_description'].str.split().str.len().mean():.2f}\")\nprint(f\"Max token count: {df['clean_task_description'].str.split().str.len().max()}\")\nprint(f\"Min token count: {df['clean_task_description'].str.split().str.len().min()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# FEATURE EXTRACTION & TASK CLASSIFICATION\n# ============================================================\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nprint(\"üõ†Ô∏è Starting Feature Extraction & Task Classification...\\n\")\n\n# Check if we have the cleaned text column\nif 'clean_task_description' not in df.columns:\n    print(\"‚ùå Error: clean_task_description column not found. Please run NLP preprocessing first.\")\n    print(\"For demonstration, we'll use the original task_description column.\\n\")\n    \n    # Create a simple preprocessing for demo purposes\n    df['clean_task_description'] = df['task_description'].fillna('').str.lower().str.replace('[^a-zA-Z\\s]', '', regex=True)\n\n# Remove rows with empty descriptions\ndf_clean = df[df['clean_task_description'].str.len() > 0].copy()\nprint(f\"Dataset shape after removing empty descriptions: {df_clean.shape}\")\n\n# Choose target variable (category for classification)\n# Let's use 'category' as our target variable\ntarget_column = 'category'\nif target_column not in df_clean.columns:\n    print(f\"‚ùå Error: {target_column} column not found.\")\n    print(\"Available columns:\", df_clean.columns.tolist())\nelse:\n    print(f\"‚úÖ Using '{target_column}' as target variable\")\n    print(f\"Categories: {df_clean[target_column].unique()}\")\n    print(f\"Category distribution:\")\n    print(df_clean[target_column].value_counts())\n    print()\n\n# Step 1: TF-IDF Feature Extraction\nprint(\"üìä Step 1: TF-IDF Feature Extraction\")\nprint(\"=\" * 40)\n\nvectorizer = TfidfVectorizer(\n    max_features=1000,  # Limit to top 1000 features\n    min_df=2,          # Ignore terms that appear in fewer than 2 documents\n    max_df=0.8,        # Ignore terms that appear in more than 80% of documents\n    ngram_range=(1, 2), # Include unigrams and bigrams\n    stop_words='english'\n)\n\n# Fit and transform the cleaned text\nX = vectorizer.fit_transform(df_clean['clean_task_description'])\ny = df_clean[target_column]\n\nprint(f\"TF-IDF matrix shape: {X.shape}\")\nprint(f\"Number of features: {X.shape[1]}\")\nprint(f\"Number of samples: {X.shape[0]}\")\nprint()\n\n# Step 2: Train-Test Split\nprint(\"üìä Step 2: Train-Test Split\")\nprint(\"=\" * 30)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(f\"Training set size: {X_train.shape[0]}\")\nprint(f\"Test set size: {X_test.shape[0]}\")\nprint(f\"Training set distribution:\")\nprint(y_train.value_counts())\nprint()\n\n# Step 3: Model Training\nprint(\"ü§ñ Step 3: Model Training\")\nprint(\"=\" * 25)\n\n# Initialize models\nmodels = {\n    'Naive Bayes': MultinomialNB(),\n    'SVM': SVC(kernel='linear', random_state=42)\n}\n\nresults = {}\n\nfor name, model in models.items():\n    print(f\"\\nTraining {name}...\")\n    \n    # Train the model\n    model.fit(X_train, y_train)\n    \n    # Make predictions\n    y_pred = model.predict(X_test)\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(y_test, y_pred)\n    results[name] = {'model': model, 'accuracy': accuracy, 'predictions': y_pred}\n    \n    print(f\"‚úÖ {name} trained successfully\")\n    print(f\"   Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n\nprint(\"\\n\" + \"=\" * 50)\nprint(\" CLASSIFICATION RESULTS SUMMARY\")\nprint(\"=\" * 50)\n\n# Display results for each model\nfor name, result in results.items():\n    accuracy = result['accuracy']\n    print(f\"\\nü§ñ {name.upper()} CLASSIFIER\")\n    print(\"-\" * 30)\n    print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n    \n    if accuracy >= 0.85:\n        print(\"‚úÖ TARGET ACHIEVED: Accuracy >= 85%\")\n    else:\n        print(\"‚ö†Ô∏è  TARGET NOT MET: Accuracy < 85%\")\n    \n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, result['predictions'], zero_division=0))\n\n# Step 4: Confusion Matrix Visualization\nprint(\"\\nüìä Step 4: Model Evaluation Visualization\")\nprint(\"=\" * 40)\n\nfig, axes = plt.subplots(1, 2, figsize=(15, 6))\n\nfor idx, (name, result) in enumerate(results.items()):\n    cm = confusion_matrix(y_test, result['predictions'])\n    \n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=model.classes_, yticklabels=model.classes_,\n                ax=axes[idx])\n    axes[idx].set_title(f'{name} - Confusion Matrix\\nAccuracy: {result[\"accuracy\"]:.2%}')\n    axes[idx].set_xlabel('Predicted')\n    axes[idx].set_ylabel('Actual')\n\nplt.tight_layout()\nplt.show()\n\n# Model Performance Comparison\nprint(\"\\nüìä Model Performance Comparison\")\nprint(\"=\" * 35)\n\nperformance_df = pd.DataFrame({\n    'Model': list(results.keys()),\n    'Accuracy': [result['accuracy'] for result in results.values()],\n    'Accuracy_Percent': [result['accuracy']*100 for result in results.values()]\n})\n\nprint(performance_df.to_string(index=False))\n\n# Determine best model\nbest_model_name = max(results.keys(), key=lambda k: results[k]['accuracy'])\nbest_accuracy = results[best_model_name]['accuracy']\n\nprint(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\nprint(f\"   Best Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n\nif best_accuracy >= 0.85:\n    print(\"\\nüéâ SUCCESS: Target accuracy of 85% achieved!\")\nelse:\n    print(\"\\n‚ö†Ô∏è  IMPROVEMENT NEEDED: Consider:\")\n    print(\"   ‚Ä¢ Hyperparameter tuning\")\n    print(\"   ‚Ä¢ Feature engineering\")\n    print(\"   ‚Ä¢ More advanced preprocessing\")\n    print(\"   ‚Ä¢ Different algorithms (Random Forest, Gradient Boosting)\")\n\nprint(\"\\n\" + \"=\" * 50)\nprint(\"‚úÖ Feature Extraction & Classification Complete!\")\nprint(\"=\" * 50)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# 1. RICH TF-IDF N-GRAMS FEATURE EXTRACTION\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"üî¨ STEP 1: RICH TF-IDF N-GRAMS (1-3) FEATURE EXTRACTION\")\nprint(\"=\"*70)\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\n# Create advanced TF-IDF vectorizer with trigrams\nvectorizer_advanced = TfidfVectorizer(\n    ngram_range=(1, 3),     # unigrams, bigrams, and trigrams\n    max_features=10000,     # significantly increased vocabulary\n    min_df=3,              # minimum document frequency\n    max_df=0.9,            # maximum document frequency\n    stop_words='english',   # remove stopwords\n    sublinear_tf=True      # use sublinear term frequency scaling\n)\n\n# Transform the cleaned task descriptions\nprint(\"\\nüìä Transforming text to TF-IDF features...\")\nX_tfidf_advanced = vectorizer_advanced.fit_transform(df_clean['clean_task_description'])\ny = df_clean['category']\n\nprint(f\"\\n‚úÖ TF-IDF Feature Extraction Complete!\")\nprint(f\"   Shape: {X_tfidf_advanced.shape}\")\nprint(f\"   Number of samples: {X_tfidf_advanced.shape[0]:,}\")\nprint(f\"   Number of features: {X_tfidf_advanced.shape[1]:,}\")\nprint(f\"   Feature types: unigrams, bigrams, trigrams\")\nprint(f\"   Vocabulary size: {len(vectorizer_advanced.vocabulary_):,}\")\n\n# Show top features\nfeature_names = vectorizer_advanced.get_feature_names_out()\nprint(f\"\\nüìù Sample features:\")\nprint(f\"   First 10: {list(feature_names[:10])}\")\nprint(f\"   Last 10: {list(feature_names[-10:])}\")\n\nprint(\"\\n\" + \"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# IMPORT NECESSARY LIBRARIES\n# ============================================================\nimport time\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# ============================================================\n# CREATE CLEAN DATAFRAME\n# ============================================================\ndf_clean = df\n\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"üîß STEP 2: SVM WITH GRID SEARCH (RBF KERNEL) OPTIMIZATION\")\nprint(\"=\"*70)\n# ============================================================\n\n# Split data into train and test sets\nprint(\"\\nüìä Splitting data into train/test sets...\")\nX_train, X_test, y_train, y_test = train_test_split(\n    X_tfidf_advanced, y, \n    test_size=0.2, \n    random_state=42, \n    stratify=y)\n\nprint(f\"\\n‚úÖ Data Split Complete!\")\nprint(f\"   Training samples: {X_train.shape[0]:,}\")\nprint(f\"   Test samples: {X_test.shape[0]:,}\")\n\n# Define parameter grid for SVM with RBF kernel\nparam_grid = {\n    'C': [0.1, 1, 10, 100],\n    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n    'class_weight': ['balanced', None]\n}\n\nprint(f\"\\nüéØ Hyperparameter Grid:\")\nprint(f\"   C values: {param_grid['C']}\")\nprint(f\"   Gamma values: {param_grid['gamma']}\")\nprint(f\"   Class weights: {param_grid['class_weight']}\")\nprint(f\"   Total combinations: {len(param_grid['C']) * len(param_grid['gamma']) * len(param_grid['class_weight'])}\")\n\n# Initialize SVM with RBF kernel\nprint(\"\\nü§ñ Initializing SVM classifier with RBF kernel...\")\nsvm_rbf = SVC(kernel='rbf', random_state=42)\n\n# Create GridSearchCV object\nprint(\"\\nüîç Starting Grid Search with 3-fold Cross-Validation...\")\nprint(\"   (This may take a few minutes...)\\n\")\n\nstart_time = time.time()\n\ngrid_search = GridSearchCV(\n    estimator=svm_rbf,\n    param_grid=param_grid,\n    cv=3,\n    n_jobs=-1,\n    verbose=2,\n    scoring='accuracy'\n)\n\n# Fit the grid search\ngrid_search.fit(X_train, y_train)\n\nend_time = time.time()\ntraining_time = end_time - start_time\n\nprint(f\"\\n‚úÖ Grid Search Complete!\")\nprint(f\"   Training time: {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n\nprint(f\"\\nüèÜ BEST PARAMETERS:\")\nfor param, value in grid_search.best_params_.items():\n    print(f\"   {param}: {value}\")\n\n# Make predictions\nprint(\"\\nüìä Making predictions on test set...\")\ny_pred_svm = grid_search.predict(X_test)\n\n# Calculate accuracy\naccuracy_svm = accuracy_score(y_test, y_pred_svm)\n\nprint(f\"\\n\" + \"=\"*70)\nprint(\"üìà SVM GRID SEARCH RESULTS\")\nprint(\"=\"*70)\nprint(f\"\\nAccuracy: {accuracy_svm:.4f} ({accuracy_svm*100:.2f}%)\")\n\nif accuracy_svm >= 0.85:\n    print(f\"‚úÖ TARGET MET: Accuracy >= 85%\")\nelse:\n    print(f\"‚ö†Ô∏è  TARGET NOT MET: Accuracy < 85%\")\n\n# Classification Report\nprint(f\"\\nüìä Classification Report:\")\nprint(classification_report(y_test, y_pred_svm))\n\n# Confusion Matrix\nprint(f\"\\nüó∫Ô∏è Confusion Matrix:\")\ncm_svm = confusion_matrix(y_test, y_pred_svm)\nprint(cm_svm)\n\nprint(\"\\n\" + \"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}